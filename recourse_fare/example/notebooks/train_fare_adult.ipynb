{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial: training FARE and E-FARE models on the Adult dataset\n",
    "\n",
    "In this notebook, we will show how to use the FARE method to generate counterfactual interventions for the Adult dataset ([Dua and Graff (2019)](https://archive.ics.uci.edu/ml/citation_policy.html)). We will explain how to train and perform inference with FARE. For this notebook, we will use a support vector machine (SVM) with an RBF kernel as the black-box model. In the paper, we used instead a trained MLP, which offers a more challenging scenario. For more additional details, you can find the original paper below:\n",
    "\n",
    "[De Toni, G., Lepri, B. & Passerini, A. Synthesizing explainable counterfactual policies for algorithmic recourse with program synthesis. Mach Learn (2023)](https://link.springer.com/article/10.1007/s10994-022-06293-7)\n",
    "\n",
    "**If have any questions or if you spot any issue with the following notebook, you can reach me at [giovanni.detoni@unitn.it](giovanni.detoni@unitn.it)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to install the library\n",
    "\n",
    "You can easily install this library thorugh pip. We suggest using Python >= 3.7 and a virtualenv (e.g., conda). In this notebook we assume to have already a suitable conda environment with all the dependencies needed.\n",
    "\n",
    "```bash\n",
    "pip install git+https://github.com/unitn-sml/recourse-fare.git@v0.1.0\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We import the SVC class and some additional preprocessing methods\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import make_column_selector, make_column_transformer\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.datasets import fetch_openml\n",
    "\n",
    "# We just need to import the FARE model from rl_mcts\n",
    "from recourse_fare.models.FARE import FARE\n",
    "from recourse_fare.models.EFARE import EFARE\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import random\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set some random seeds to ensure reproducibility\n",
    "random.seed(2023)\n",
    "np.random.seed(2023)\n",
    "torch.manual_seed(2023)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preprocessing\n",
    "\n",
    "We first retrieve the Adult dataset and complete some data cleaning activity. We first split the dataset into training and testing, and then we mainly perform two actions:\n",
    "* We convert the `target` variable to either 0 (`>50K`) or 1 (`<=50K`);\n",
    "* We replace unknown entries with `?` with the most frequent element for that given column. The most frequent element is taken by looking at the training set only and then by using those values to input the test set;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We fetch the adult dataset from openml repository\n",
    "data = fetch_openml(name='adult', version=2)\n",
    "X = data.get(\"data\").copy()\n",
    "X[\"target\"] = data.get(\"target\").values\n",
    "\n",
    "# Drop NaNs in the dataset\n",
    "X.dropna(inplace=True)\n",
    "\n",
    "# We drop some columns we do not consider actionable. It makes the problem less interesting, but it does\n",
    "# show the point about how counterfactual interventions works. \n",
    "X.drop(columns=[\"fnlwgt\", \"age\", \"education-num\", \"race\", \"sex\", \"native-country\", \"relationship\"], inplace=True)\n",
    "\n",
    "y = X.target.apply(lambda x: 1 if x==\"<=50K\" else 0)\n",
    "X.drop(columns=[\"target\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset into train/test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=2023)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the most frequent attributes for the features with '?' values.\n",
    "# We compute the most frequent attributes by looking at the training set only.\n",
    "attrib, counts = np.unique(X_train['workclass'], return_counts = True)\n",
    "most_freq_attrib_w = attrib[np.argmax(counts, axis = 0)]\n",
    "\n",
    "attrib, counts = np.unique(X_train['occupation'], return_counts = True)\n",
    "most_freq_attrib_o = attrib[np.argmax(counts, axis = 0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We define a simple utility function which replaces the '?' with custom values\n",
    "def clean(data, most_freq_attrib_o, most_freq_attrib_w, most_freq_attrib_c):\n",
    "    data['occupation'] = data['occupation'].apply(lambda x: most_freq_attrib_o if x=='?' else x)\n",
    "    data['workclass'] = data['workclass'].apply(lambda x: most_freq_attrib_w if x=='?' else x)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We apply the clean() function both to the training and test set.\n",
    "X_train = clean(X_train, most_freq_attrib_o, most_freq_attrib_w, None)\n",
    "X_test = clean(X_test, most_freq_attrib_o, most_freq_attrib_w, None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing Pipeline with scikit-learn\n",
    "\n",
    "We then build a preprocessor to standardize/encode the various features. Namely, we use a `StandardScaler` and an `OneHotEncoder` to manage the real and categorical features, respectively. We exploit the `ColumnTransformer` class of scikit-learn to build a complete preprocessing pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a preprocessing pipeline, which can be used to preprocess\n",
    "# the elements of the dataset.\n",
    "cat_selector = make_column_selector(dtype_include=[object, \"category\"])\n",
    "num_selector = make_column_selector(dtype_include=np.number)\n",
    "preprocessor = make_column_transformer(\n",
    "    (StandardScaler(), num_selector), (OneHotEncoder(handle_unknown=\"ignore\",sparse=False), cat_selector)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the preprocessor on the training data \n",
    "preprocessor.fit(X_train);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train and evaluating the black-box model\n",
    "\n",
    "We train a simple `SVC` class in a \"balanced\" mode, where the misclassification errors are weighted by the relative numerosity of a class. Adult is an unbalanced dataset, thus we need to make sure that our model has a decent F1 score rather than just looking at the accuracy.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.55      0.67      3392\n",
      "           1       0.78      0.95      0.86      5653\n",
      "\n",
      "    accuracy                           0.80      9045\n",
      "   macro avg       0.82      0.75      0.77      9045\n",
      "weighted avg       0.81      0.80      0.79      9045\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Fit a simple SVC model over the data\n",
    "blackbox_model = SVC(class_weight=\"balanced\")\n",
    "blackbox_model.fit(preprocessor.transform(X_train), y_train)\n",
    "\n",
    "# Evaluate the model and print the classification report for the two classes\n",
    "output = blackbox_model.predict(preprocessor.transform(X_test))\n",
    "print(classification_report(output, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter the training dataset by picking only the examples which are classified negatively by the model\n",
    "output = blackbox_model.predict(preprocessor.transform(X_train))\n",
    "X_train[\"predicted\"] = output\n",
    "X_train = X_train[X_train.predicted == 1]\n",
    "X_train.drop(columns=\"predicted\", inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FARE Model\n",
    "\n",
    "Now comes the interesting part. We are going to show how to train the FARE model on the Adult dataset. The FARE model needs three different configurations parameters:\n",
    "* **Policy Configuration**: it specifies how to build the internal agent. Please have a look at Figure 3 of the paper to understand the policy architecture.\n",
    "* **Environment Configuration**: it specifies the environment where our agent will work on. Please have a look at the original implementation `recourse_fare/example/mock_adult_env.py` to understand its internal components.\n",
    "* **MCTS Configuration**: it specifies some hyperparameters of the MCTS search component. \n",
    "\n",
    "In the cell below we show what we think are the most important configuration parameters for each component. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "policy_config= {\n",
    "    \"observation_dim\": 47, # Size of the state's observation (after using the preprocessor defined above).\n",
    "    \"encoding_dim\": 30, # Size of the output embedding of the state encoder. \n",
    "    \"hidden_size\": 30 # Size of the hiddel layers of the controller (LSTM).\n",
    "}\n",
    "\n",
    "environment_config = {\n",
    "    \"class_name\": \"recourse_fare.example.mock_adult_env.AdultEnvironment\", # Class implementing the environment.\n",
    "    \"additional_parameters\": {\n",
    "        \"preprocessor\": preprocessor    # ColumnTransformer which is used to parse the environment. \n",
    "                                        # It is not a mandatory argument, but it is required by the AdultEnvironment class.\n",
    "    }\n",
    "}\n",
    "\n",
    "mcts_config = {\n",
    "    \"number_of_simulations\": 10, # How many simulations we want to perform at each MCTS node.\n",
    "    \"dir_epsilon\": 0.3, # Parameter trading off exploration and exploitation (1.0 = only exploration).\n",
    "    \"dir_noise\": 0.3 # Concentration parameter of the Dirichlet distribution used as \"noise\".\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We build a FARE model by giving the constructor the `blackbox_model` and the configurations defined above. The `batch_size` indicates how many successful samples we need at each training step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train a FARE model given the previous configurations\n",
    "model = FARE(blackbox_model, policy_config, environment_config, mcts_config, batch_size=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the FARE model\n",
    "\n",
    "If you have done all correctly, training the FARE model is as easy as calling the `fit()` method as shown below. However, under certain conditions, the training accuracy might struggle to increase to a satisfactory level. Here we give some suggestions we learned during our experiments:\n",
    "1. **Increase the `max_intervention_depth` value**. Such value indicates how long an intervention can be (e.g., how many actions the user might want to perform). Therefore, if a user needs to modify $N$ of its features to obtain recourse, a `max_intervention_depth` lower than $N$ might make the model unable to learn succesful interventions. As a rule of thumb, we suggest to set the `max_intervention_depth` value to at least $\\frac{N}{2}$, where $N$ is the number of features.\n",
    "2. **Improve the actions**. It might happen that the actions defined in the environment class might not be enough to obtain recourse. This situation might arise in two cases: either we are supplying to few arguments to an action (it means we might miss some potential good changes which could lead to recourse), or either the black-box classifier is making decisions based on non-actionable features (e.g., age, sex, native country etc.). In the latter case, there is little we can do, and it could be a hint that we trained an \"unfair\" model.\n",
    "3. **Increase the `dir_epsilon` value**. Sometimes, it might happen that we do not provide enough noise to explore a potentially large actions space, thus, limiting the overall exploration.\n",
    "\n",
    "If we specify the `tensorboard` argument, the FARE model will save training statistics in a directory. We can read them by using tensorboard. This feature is useful to check if the training is progressing correctly or if we need to take additional correction steps based on the suggestions above. If you want to display the information through tensorboard, then you need to run:\n",
    "```\n",
    "tensorboard --logdir ../notebooks/runs/adult\n",
    "```\n",
    "\n",
    "#### Note on the `max_iter` parameter\n",
    "\n",
    "The `max_iter` parameter had a double meaning. It corresponds to how many potentially **different** users we sample from the training dataset and how many **training steps** we are performing. So, if we set 5000 as `max_iter`, we will sample at least 5000 users. However, we might perform fewer training steps (e.g., gradient updates). This behaviour depends on the `batch_size` parameter that indicates the minimum number of examples (sampled from the training buffer) we can use to train the model. Finding good interventions via MCTS might be hard and the training buffer would get slowly populated over each iterations. Therefore, we will not start training the underlying agent until we get `len(training_buffer) >= batch_size`     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da47d76ed7674cdfa729e2cd632f08ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train FARE:   0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# We fit the FARE model with tensorboard enabled.\n",
    "# We need to make sure that the directory `../notebooks/runs/adult` exists\n",
    "# since it is not created automatically.\n",
    "model.fit(X_train, max_iter=500, tensorboard=\"../notebooks/runs/adult\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We save the trained FARE model to disk\n",
    "model.save(\"/tmp/fare.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load a pre-trained FARE model for the Adult dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We load a pretrained model from a previous checkpoint\n",
    "pretrained_model = \"../notebooks/models/fare_adult-17_03_2023.pth\"\n",
    "model.load(pretrained_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We use only the data which are negatively classified for testing\n",
    "output = blackbox_model.predict(preprocessor.transform(X_test))\n",
    "X_test[\"predicted\"] = output\n",
    "X_test = X_test[X_test.predicted == 1]\n",
    "X_test.drop(columns=\"predicted\", inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we load the pretrained FARE model, we can run inference over the test instances. By specifying `full_output=True`, we fetch additional information from the model. Namely, we obtain the **counterfactual instances**, the **recourse results** (1 if we got recourse, 0 otherwise), the **counterfactual interventions** and the **costs** of those interventions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e521c462179049e1944625bdf22c741a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Eval FARE:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# We run inference using FARE over 10 examples taken from the test set\n",
    "counterfactuals, has_reached_recourse, traces, costs, _ = model.predict(X_test[0:100], full_output=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now compute the $validity$, fraction of successful interventions we could find."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validity: 0.84\n"
     ]
    }
   ],
   "source": [
    "print(f\"Validity: {sum(has_reached_recourse)/(len(has_reached_recourse))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also extract an example of a counterfactual intervention (with both actions and arguments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['CHANGE_WORKCLASS', 'Private'],\n",
      " ['CHANGE_EDUCATION', 'Prof-school'],\n",
      " ['STOP', 0]]\n"
     ]
    }
   ],
   "source": [
    "import pprint\n",
    "print(pprint.pformat(traces[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train an E-FARE deterministic model\n",
    "\n",
    "We now show how to train the deterministic model E-FARE, that will allow us to extract an automaton from the successful interventions. E-FARE also produces boolean rules that explain why the model suggested each of the actions in the intervention. The interface of the `EFARE` class is similar to the `FARE` API. For more the details of the E-FARE procedure, we point the reader to Section 3.6 and Section 3.7 of the paper."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data preprocessing for E-FARE\n",
    "\n",
    "E-FARE trains a series of decision trees, one for each action available. If we want to have interpretable rules, we need to make our observations interpretable. For the Adult dataset, we keep the numerical values as they are, but we one hot encode the categorical values.    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_selector = make_column_selector(dtype_include=[object, \"category\"])\n",
    "preprocessor_efare = make_column_transformer(\n",
    "    (OneHotEncoder(handle_unknown=\"ignore\",sparse=False), cat_selector), remainder=\"passthrough\"\n",
    ")\n",
    "\n",
    "# We fit the EFARE preprocessor\n",
    "preprocessor_efare.fit(X_train);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The E-FARE model needs only the pretrained FARE model and a preprocessor (which could be the same used by the FARE model) as arguments. Then, training it and saving it to disk are straightforward steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b1893570658408a8334ae9b40c870f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Eval FARE:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*] Compute rules given graph\n",
      "[*] Getting rules for node INTERVENE\n",
      "[*] Getting rules for node CHANGE_WORKCLASS\n",
      "[*] Getting rules for node CHANGE_OCCUPATION\n",
      "[*] Getting rules for node CHANGE_EDUCATION\n"
     ]
    }
   ],
   "source": [
    "# We instantiate the EFARE model, we train it over 100 examples from the training set and we save it to disk.\n",
    "efare_model = EFARE(model, preprocessor_efare)\n",
    "efare_model.fit(X_train[0:100], verbose=True)\n",
    "efare_model.save(\"/tmp/efare.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# As we did for the FARE model, we load a pre-trained E-FARE model which will give us a decent validity\n",
    "efare_model.load(\"../notebooks/models/efare_adult-17_03_2023.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `predict` API is the same as the `FARE` model. The only difference is that it returns the **rules** from the decision trees for each action. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c6d0c66030b641549e94b71e2aeb355e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Eval EFARE:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# We run inference using E-FARE\n",
    "counterfactuals, has_reached_recourse, traces, costs, rules = efare_model.predict(X_test[0:100], full_output=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define a small function to parse the rules in an intelligible shape. It might be a bit cumbersome and depends on the preprocessing step. However, it is just for markup purposes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to clean up the rules extracted from EFARE\n",
    "def clean_rules(rules):\n",
    "    new_rule = []\n",
    "    for single_rule in rules:\n",
    "        tmp_rule = []\n",
    "        for clause in single_rule:\n",
    "            if \"onehotencoder__\" in clause:\n",
    "                # This branch checks if the rule comes from an one-hot-encoded variable\n",
    "                clause = clause.replace(\"onehotencoder__\", \"\")             \n",
    "                if \"<= 0.5\" in clause:\n",
    "                    negation = \"not\"\n",
    "                else:\n",
    "                    negation = \"\"            \n",
    "                clause = clause.replace(\"<= 0.5\", \"\")\n",
    "                clause = clause.replace(\"> 0.5\", \"\")            \n",
    "                feature, value = clause.rsplit('_', 1)            \n",
    "                final_clause = negation+\" \"+feature+\" = \"+value\n",
    "                tmp_rule.append(final_clause.strip())             \n",
    "            elif \"remainder__\" in clause:\n",
    "                clause = clause.replace(\"remainder__\", \"\")    \n",
    "                tmp_rule.append(clause)     \n",
    "        new_rule.append(\" and \".join(tmp_rule))\n",
    "    return new_rule"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have this function, we can easily use it to compute the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example of rules extracted by E-FARE:\n",
      "['CHANGE_EDUCATION', 'Prof-school'] \t not workclass = State-gov and capital-loss <= 795.0 and not workclass = Federal-gov and education = Assoc-acdm and not marital-status = Divorced\n",
      "['CHANGE_OCCUPATION', 'Tech-support'] \t hours-per-week <= 42.5 and not occupation = Farming-fishing and not occupation = Sales and not occupation = Tech-support and hours-per-week <= 36.5\n",
      "['STOP', 0] \t education = Prof-school\n"
     ]
    }
   ],
   "source": [
    "# We can print the rules for a given user\n",
    "import pprint\n",
    "\n",
    "print(\"Example of rules extracted by E-FARE:\")\n",
    "for action, rule in zip(traces[0], clean_rules(rules[0])):\n",
    "    print(action, \"\\t\", rule)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At last, we compute the validity of EFARE. Clearly, we will get similar results to the FARE model. For the advantages of EFARE with respect to FARE, please have a look at the relevant section of the paper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validity: 0.89\n"
     ]
    }
   ],
   "source": [
    "print(f\"Validity: {sum(has_reached_recourse)/(len(has_reached_recourse))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rl-mcts",
   "language": "python",
   "name": "rl-mcts"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
